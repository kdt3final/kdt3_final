{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNN8CHwLnVaQ",
        "outputId": "6c40ae8c-07ff-4bc0-bfc1-6e8030cb7d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# 구글 드라이브 마운트\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "2fXR2jqhn3uW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 파일 로딩\n",
        "with open('/content/labels_updated.json', 'r') as file:\n",
        "    labels = json.load(file)\n",
        "\n",
        "# 사용할 감정 리스트\n",
        "valid_emotions = [\"sadness\", \"happy\", \"anger\", \"panic\"]\n",
        "\n",
        "# 데이터와 라벨을 저장할 리스트\n",
        "data = []\n",
        "label_list = []\n",
        "\n",
        "# 이미지 파일 로딩 및 필터링\n",
        "for item in labels:\n",
        "    img_path = item['image']\n",
        "    emotion = item['emotion']\n",
        "\n",
        "    # 유효한 감정인지 확인\n",
        "    if emotion in valid_emotions:\n",
        "        # 이미지 로딩 및 전처리\n",
        "        img_path = img_path.replace(\"C:\\\\Users\\\\user\\\\Desktop\\\\Final Project\\\\Images Data\\\\ESTSOFT_Cropped\\\\img\\\\\", \"/content/drive/My Drive/img/\")\n",
        "        image = load_img(img_path, target_size=(224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        # 리스트에 추가\n",
        "        data.append(image)\n",
        "        label_list.append(emotion)\n",
        "\n",
        "# 데이터가 로드되었는지 확인\n",
        "print(f\"Loaded {len(data)} images with labels.\")\n",
        "\n",
        "# 데이터가 존재하는지 확인\n",
        "if len(data) == 0 or len(label_list) == 0:\n",
        "    raise ValueError(\"No data or labels loaded. Please check the dataset.\")\n",
        "\n",
        "# 리스트를 넘파이 배열로 변환\n",
        "data = np.array(data)\n",
        "label_list = np.array(label_list)\n",
        "\n",
        "# 라벨 이진화 (One-hot encoding)\n",
        "lb = LabelBinarizer()\n",
        "label_list = lb.fit_transform(label_list)\n",
        "\n",
        "# 학습 데이터셋과 검증 데이터셋 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, label_list, test_size=0.2, random_state=42)\n",
        "\n",
        "# VGG16 모델 불러오기 (ImageNet 가중치 사용, 최상위 Fully Connected Layer 제외)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 최상위 Layer 추가\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(len(lb.classes_), activation='softmax')(x)\n",
        "\n",
        "# 새로운 모델 정의\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 최상위 Layer만 학습\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
        "\n",
        "# 검증 데이터셋에 대한 예측\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# y_pred와 y_val의 차원 확인 후 변환\n",
        "if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "else:\n",
        "    y_pred_classes = y_pred  # 차원이 1인 경우 직접 사용\n",
        "\n",
        "if len(y_val.shape) > 1 and y_val.shape[1] > 1:\n",
        "    y_true_classes = np.argmax(y_val, axis=1)\n",
        "else:\n",
        "    y_true_classes = y_val  # 차원이 1인 경우 직접 사용\n",
        "\n",
        "# 성능 평가\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=lb.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjM3_9tcbi98",
        "outputId": "7b8909d0-accf-4ed8-a56e-b750b780c6a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5994 images with labels.\n",
            "Epoch 1/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 0.3908 - loss: 9.2486 - val_accuracy: 0.5063 - val_loss: 1.0958\n",
            "Epoch 2/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 98ms/step - accuracy: 0.7113 - loss: 0.7096 - val_accuracy: 0.6464 - val_loss: 0.9246\n",
            "Epoch 3/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 97ms/step - accuracy: 0.8971 - loss: 0.3050 - val_accuracy: 0.6505 - val_loss: 1.1199\n",
            "Epoch 4/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - accuracy: 0.9661 - loss: 0.1208 - val_accuracy: 0.6847 - val_loss: 1.0585\n",
            "Epoch 5/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.9936 - loss: 0.0420 - val_accuracy: 0.6764 - val_loss: 1.2113\n",
            "Epoch 6/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.9989 - loss: 0.0144 - val_accuracy: 0.6689 - val_loss: 1.4566\n",
            "Epoch 7/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - accuracy: 0.9996 - loss: 0.0114 - val_accuracy: 0.6839 - val_loss: 1.3299\n",
            "Epoch 8/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.6781 - val_loss: 1.3942\n",
            "Epoch 9/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 97ms/step - accuracy: 0.9994 - loss: 0.0042 - val_accuracy: 0.6906 - val_loss: 1.4339\n",
            "Epoch 10/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.9990 - loss: 0.0065 - val_accuracy: 0.6939 - val_loss: 1.3996\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.60      0.58      0.59       293\n",
            "       happy       0.77      0.82      0.80       300\n",
            "       panic       0.75      0.68      0.71       279\n",
            "     sadness       0.66      0.69      0.67       327\n",
            "\n",
            "    accuracy                           0.69      1199\n",
            "   macro avg       0.69      0.69      0.69      1199\n",
            "weighted avg       0.69      0.69      0.69      1199\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9P-5-jLpn9tP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}